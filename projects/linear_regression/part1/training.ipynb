{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from getData import getDataSplits\n",
    "\n",
    "learning_rate = 10e-6\n",
    "max_epochs = 100_000\n",
    "error_threshold = 10e-5\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      " GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research  Chance of Admit\n",
      "       316          107                  2  3.5  3.5  8.64         1             0.57\n",
      "       315          104                  3  4.0  2.5  8.10         0             0.65\n",
      "       318          107                  3  3.0  3.5  8.27         1             0.74\n",
      "       314          105                  2  2.5  2.0  7.64         0             0.70\n",
      "       301          107                  3  3.5  3.5  8.34         1             0.62\n"
     ]
    }
   ],
   "source": [
    "train, test = getDataSplits()\n",
    "\n",
    "print(train.head().to_string(index=False))\n",
    "\n",
    "x_train = train.copy()\n",
    "y_train = train['Chance of Admit']\n",
    "x_train = x_train.drop(columns=['Chance of Admit'])\n",
    "\n",
    "x_test = test.copy()\n",
    "y_test = test['Chance of Admit']\n",
    "x_test = x_test.drop(columns=['Chance of Admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's recap things\n",
    "\n",
    "Model is Linear Regression:\n",
    "\n",
    "y_hat = w.T * x + b\n",
    "\n",
    "We will need to set an loss function to minimize. We will use the Mean Squared Error (MSE) function.\n",
    "\n",
    "MSE = 1/n * sum((y_hat - y)^2) =>\n",
    "L = 1/n * sum((w.T * x + b - y)^2)\n",
    "\n",
    "We will use the gradient descent algorithm to minimize the loss function. The gradient of the loss function with respect to the weights and bias is given by:\n",
    "\n",
    "Repeat until convergence\n",
    "w <- w - alpha * dL/dw\n",
    "b <- b - alpha * dL/db\n",
    "\n",
    "Where alpha is the learning rate.\n",
    "We'll add b to w matrix. So, w = [w, b]\n",
    "So now we need to minimize ||w.T * x - y||^2\n",
    "\n",
    "The gradient of the loss function with respect to the weights and bias is given by:\n",
    "dL/dw = 2/n * sum((w.T * x - y) * x)\n",
    "\n",
    "We need to chose a learning rate and a Error to run the algorithm.\n",
    "\n",
    "alpha = 10E-2 or 10E-3\n",
    "Error = 10E-3 or 10E-4\n",
    "\n",
    "iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5000000000000002e-08"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "\n",
    "learning_rate/len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "# add the bias term\n",
    "w = np.array([1])\n",
    "# add the weights for each feature randomly\n",
    "w = np.append(w, np.random.rand(x_train.shape[1]))\n",
    "\n",
    "\n",
    "delta_Error = 1\n",
    "old_Error = 0\n",
    "ephocs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, y_hat):\n",
    "    return np.mean((y - y_hat) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.444798   0.02211118 0.60598834 0.96479652 0.96759148\n",
      " 0.93002881 0.18467983] \n",
      "\n",
      "[160.11752686 159.04029506 160.78660227 155.65281612 153.77253659] \n",
      "\n",
      "[0.57 0.65 0.74 0.7  0.62] \n",
      "\n",
      "25610.040097322828 \n",
      "\n",
      "[ 0.99840136 -0.06155709 -0.14956502  0.6009432   0.95939457  0.96196694\n",
      "  0.91630951  0.18377159] \n",
      "\n",
      "[-18.4297593  -18.47941232 -18.77066209 -21.50994116 -17.18035259] \n",
      "\n",
      "[0.57 0.65 0.74 0.7  0.62] \n",
      "\n",
      "357.93733359035707 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "while delta_Error > error_threshold:\n",
    "\n",
    "    # if we reach the max number of epochs, we stop\n",
    "    ephocs += 1\n",
    "    if ephocs > max_epochs:\n",
    "        break\n",
    "\n",
    "    y_hat = np.dot(x_train, w[1:]) + w[0]\n",
    "    print(w, \"\\n\")\n",
    "    print(y_hat[:5], \"\\n\")\n",
    "    print(y_train[:5], \"\\n\")\n",
    "\n",
    "   \n",
    "    \n",
    "    w[0] = w[0] - learning_rate/len(x_train) * np.sum(y_hat - y_train)\n",
    "\n",
    "    w[1:] = w[1:] - learning_rate/len(x_train) * np.dot((y_hat - y_train), x_train)\n",
    "\n",
    "    error = MSE(y_train, y_hat) \n",
    "    print(error, \"\\n\")\n",
    "\n",
    "    if ephocs == 2:\n",
    "        break\n",
    "\n",
    "    delta_Error = abs(old_Error - error)\n",
    "    old_Error = error\n",
    "\n",
    "    if delta_Error < error_threshold:\n",
    "        print('we reached the error threshold')\n",
    "        print(f'Error: {error} Delta Error: {delta_Error} Epochs: {ephocs}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
